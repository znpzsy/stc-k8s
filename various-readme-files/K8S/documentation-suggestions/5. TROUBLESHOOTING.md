# Troubleshooting Guide

This guide covers common issues across all deployment methods with step-by-step solutions.

## ðŸ“‹ Table of Contents

1. [Docker Compose Issues](#docker-compose-issues)
2. [Local Kubernetes Issues](#local-kubernetes-issues)
3. [Corporate Kubernetes Issues](#corporate-kubernetes-issues)
4. [Network and Port Issues](#network-and-port-issues)
5. [Image and Registry Issues](#image-and-registry-issues)
6. [Application-Specific Issues](#application-specific-issues)

---

## Docker Compose Issues

### Issue: "Port already in use"

**Error:**
```
Error starting userland proxy: listen tcp4 0.0.0.0:80: bind: address already in use
```

**Solution 1: Kill the process using the port**
```bash
# Find what's using port 80
lsof -ti:80

# Kill the process
lsof -ti:80 | xargs kill

# Or for other ports
lsof -ti:443 | xargs kill
lsof -ti:8080 | xargs kill
```

**Solution 2: Change ports in docker-compose**
```yaml
# Edit docker-compose_dev.yml
services:
  httpd:
    ports:
      - '8080:80'    # Change from 80:80
      - '8443:443'   # Change from 443:443
```

### Issue: "Cannot connect to Docker daemon"

**Error:**
```
Cannot connect to the Docker daemon. Is the docker daemon running?
```

**Solution:**
```bash
# On Mac/Windows
# Start Docker Desktop application

# Verify Docker is running
docker ps

# If still issues, restart Docker Desktop
```

### Issue: Hot-reload not working

**Symptoms:**
- Change files but don't see updates
- Need to restart containers for changes

**Solution:**
```bash
# 1. Check if volumes are mounted correctly
docker inspect <container-id> | grep Mounts -A 20

# 2. Ensure you're using docker-compose_dev.yml (not prod)
docker compose -f docker-compose_dev.yml up

# 3. For gulp-based portals, check gulp is running
docker logs <portal-container> | grep gulp

# 4. Force restart if needed
docker exec -it <container-name> pm2 restart all
```

### Issue: "Build failed" or "Cannot find package"

**Error:**
```
npm ERR! code ENOENT
npm ERR! syscall open
npm ERR! path /app/package.json
```

**Solution:**
```bash
# 1. Clean Docker cache
docker builder prune -a

# 2. Rebuild without cache
make rebuild dev

# Or
docker compose -f docker-compose_dev.yml build --no-cache

# 3. If still failing, check Dockerfile context
# Make sure Dockerfile.dev is in the right directory
```

### Issue: "Container exits immediately"

**Symptoms:**
- Container shows in `docker ps -a` but not in `docker ps`
- Status shows "Exited (1)"

**Solution:**
```bash
# 1. Check logs
docker logs <container-name>

# 2. Common causes:
# - Missing dependencies (check package.json)
# - Wrong command in Dockerfile
# - Configuration errors

# 3. Try running interactively
docker run -it <image-name> /bin/bash
# Then manually run the start command to see errors
```

### Issue: "Network not found"

**Error:**
```
ERROR: Network vcp-network declared as external, but could not be found
```

**Solution:**
```bash
# 1. Remove the network declaration from docker-compose
# Edit docker-compose_dev.yml and check networks section

# 2. Let Docker Compose create it automatically
docker compose -f docker-compose_dev.yml up --build

# 3. Or create manually
docker network create vcp-network
```

---

## Local Kubernetes Issues

### Issue: "Kubernetes is not running"

**Error:**
```
The connection to the server localhost:8080 was refused
```

**Solution:**
```bash
# On Docker Desktop:
# 1. Settings â†’ Kubernetes â†’ Enable Kubernetes
# 2. Wait for green indicator
# 3. Apply & Restart if needed

# Verify:
kubectl cluster-info
kubectl get nodes

# If still not working:
# Settings â†’ Reset Kubernetes Cluster
```

### Issue: "ImagePullBackOff" or "ErrImagePull"

**Error:**
```
Failed to pull image "stc-vcp/httpd:latest": rpc error: code = Unknown
```

**Solution:**

**For NodePort/ClusterIP (local images):**
```bash
# 1. Check if image exists locally
docker images | grep stc-vcp

# 2. If not, build it
docker compose -f docker-compose_dev.yml build

# 3. Verify tag matches values file
# In values-local.yaml, check:
#   tag: latest  (not 1.0.0.1-amd64)

# 4. If using custom tag, ensure it's built
docker tag stc-vcp/httpd:latest stc-vcp/httpd:1.0.0.1
```

**For corporate registry:**
```bash
# 1. Check image exists in registry
docker pull nexus.telenity.com/com/telenity/consolportals-sa-stc-vcp-httpd:1.0.0.1-amd64

# 2. If not, push it
docker push nexus.telenity.com/com/telenity/consolportals-sa-stc-vcp-httpd:1.0.0.1-amd64

# 3. Check imagePullPolicy in deployment
kubectl describe pod <pod-name> -n stc-vcp-services | grep "Pull"
# Should be: IfNotPresent for local
```

### Issue: "CrashLoopBackOff"

**Error:**
```
NAME                          READY   STATUS             RESTARTS
httpd-xxx                     0/1     CrashLoopBackOff   5
```

**Solution:**
```bash
# 1. Check pod logs (most important!)
kubectl logs <pod-name> -n stc-vcp-services

# 2. Check previous logs if container restarted
kubectl logs <pod-name> -n stc-vcp-services --previous

# 3. Describe pod for events
kubectl describe pod <pod-name> -n stc-vcp-services

# 4. Common causes:
# - Application error (check logs)
# - Missing configuration (ConfigMaps)
# - Port conflicts
# - Resource limits too low

# 5. Try running the container locally to debug
docker run -it <image-name> /bin/bash
```

### Issue: "Cannot access service" (Connection refused)

**Symptoms:**
- Pods are running
- Can't access at localhost:30080 (NodePort) or localhost:9080 (port-forward)

**Solution:**

**For NodePort:**
```bash
# 1. Verify service is NodePort type
kubectl get svc -n stc-vcp-services
# Should show TYPE: NodePort

# 2. Check NodePort assignment
kubectl describe svc consolportals-sa-stc-vcp-httpd-service -n stc-vcp-services
# Look for: NodePort: http 30080/TCP

# 3. Verify pods are running
kubectl get pods -n stc-vcp-services

# 4. Test service internally first
kubectl port-forward svc/consolportals-sa-stc-vcp-httpd-service 8888:80 -n stc-vcp-services
curl http://localhost:8888

# 5. If internal works but NodePort doesn't:
# Check Docker Desktop networking or firewall
```

**For Port-Forward:**
```bash
# 1. Check port-forward is running
ps aux | grep "kubectl port-forward"

# 2. If not running, start it
kubectl port-forward svc/consolportals-sa-stc-vcp-httpd-service 9080:80 -n stc-vcp-services &

# 3. Check for port conflicts
lsof -ti:9080 | xargs kill  # Kill conflicts
# Then restart port-forward
```

**For Ingress:**
```bash
# 1. Check NGINX Ingress Controller is running
kubectl get pods -n ingress-nginx

# 2. Check ingress resource
kubectl get ingress -n stc-vcp-services
kubectl describe ingress consolportals-sa-stc-vcp-ingress -n stc-vcp-services

# 3. Check ingress controller logs
kubectl logs -n ingress-nginx deployment/ingress-nginx-controller

# 4. Verify ingress host matches your access URL
# In values.yaml:
#   ingress.host: localhost  (for local)
```

### Issue: Helm install fails

**Error:**
```
Error: rendered manifests contain a resource that already exists
```

**Solution:**
```bash
# 1. Check if release already exists
helm list -n stc-vcp-services

# 2. If exists, either upgrade or uninstall
helm upgrade consolportals . -f values-local.yaml -n stc-vcp-services
# OR
helm uninstall consolportals -n stc-vcp-services

# 3. Then reinstall
helm install consolportals . -f values-local-nodeport.yaml -n stc-vcp-services
```

**Error:**
```
Error: YAML parse error on
```

**Solution:**
```bash
# 1. Validate Helm chart syntax
helm lint .

# 2. Dry-run to see rendered templates
helm install consolportals . --dry-run --debug -n stc-vcp-services

# 3. Check for YAML indentation issues
# Common culprits: templates/*.yaml, values.yaml
```

### Issue: Persistent "Pending" pods

**Symptoms:**
```
NAME                          READY   STATUS    RESTARTS
httpd-xxx                     0/1     Pending   0
```

**Solution:**
```bash
# 1. Describe pod to see why
kubectl describe pod <pod-name> -n stc-vcp-services

# 2. Common causes:
# - Insufficient resources (memory/CPU)
# - Node selector mismatch
# - PVC not available (if using persistent volumes)

# 3. Check node resources
kubectl describe node

# 4. For resource issues, reduce in values file:
httpd:
  resources:
    enabled: false  # Disable resource limits

# Or increase Docker Desktop resources:
# Settings â†’ Resources â†’ Increase Memory/CPU
```

---

## Corporate Kubernetes Issues

### Issue: "Access Denied" to namespace

**Error:**
```
Error from server (Forbidden): pods is forbidden: User "xxx" cannot list resource "pods" in API group
```

**Solution:**
```bash
# 1. Verify you have correct kubectl context
kubectl config get-contexts
kubectl config use-context <corporate-context>

# 2. Check if namespace exists
kubectl get namespaces | grep stc-vcp-services

# 3. Verify your permissions
kubectl auth can-i list pods -n stc-vcp-services

# 4. Contact cluster admin if no access
# You may need RoleBindings or ClusterRoleBindings
```

### Issue: Images won't pull from Nexus

**Error:**
```
Failed to pull image "nexus.telenity.com/...": authentication required
```

**Solution:**
```bash
# 1. Login to Nexus
docker login nexus.telenity.com

# 2. Test pull locally
docker pull nexus.telenity.com/com/telenity/consolportals-sa-stc-vcp-httpd:1.0.0.1-amd64

# 3. For cluster, check ImagePullSecrets
kubectl get secrets -n stc-vcp-services

# 4. If missing, create secret (contact admin for credentials)
kubectl create secret docker-registry nexus-credentials \
  --docker-server=nexus.telenity.com \
  --docker-username=<username> \
  --docker-password=<password> \
  -n stc-vcp-services

# 5. Reference in deployment:
imagePullSecrets:
  - name: nexus-credentials
```

### Issue: "exec format error" on corporate cluster

**Error:**
```
standard_init_linux.go: exec user process caused: exec format error
```

**Cause:** Image built for wrong architecture (ARM instead of AMD64)

**Solution:**
```bash
# 1. Check image architecture
docker inspect nexus.telenity.com/.../httpd:1.0.0.1-amd64 | grep Architecture
# Must show: "Architecture": "amd64"

# 2. Rebuild for AMD64 explicitly
docker buildx build --platform linux/amd64 \
  -t nexus.telenity.com/com/telenity/consolportals-sa-stc-vcp-httpd:1.0.0.2-amd64 \
  -f httpd/Dockerfile.vcp.prod \
  ./httpd

# 3. Push new image
docker push nexus.telenity.com/com/telenity/consolportals-sa-stc-vcp-httpd:1.0.0.2-amd64

# 4. Update values.yaml with new tag
# Change to: tag: 1.0.0.2-amd64

# 5. Upgrade deployment
helm upgrade consolportals . -f values.yaml -n stc-vcp-services
```

### Issue: Cannot access via Ingress hostname

**Symptoms:**
- Pods running fine
- Cannot access https://consolportals.internal.telenity.com

**Solution:**
```bash
# 1. Check ingress is created
kubectl get ingress -n stc-vcp-services

# 2. Check ingress status and rules
kubectl describe ingress consolportals-sa-stc-vcp-ingress -n stc-vcp-services

# 3. Test from within cluster (to rule out DNS)
kubectl run curl-test --image=curlimages/curl --rm -it --restart=Never -- \
  curl -H "Host: consolportals.internal.telenity.com" http://httpd-service

# 4. Check DNS resolution
nslookup consolportals.internal.telenity.com

# 5. Check ingress controller
kubectl get pods -n ingress-nginx  # or your ingress controller namespace
kubectl logs -n ingress-nginx deployment/ingress-nginx-controller

# 6. Verify ingress class
kubectl describe ingress consolportals-sa-stc-vcp-ingress -n stc-vcp-services | grep Class
# Should match your cluster's ingress controller
```

---

## Network and Port Issues

### Issue: "Connection refused" on localhost

**For Docker Compose:**
```bash
# 1. Check containers are running
docker ps

# 2. Check port mappings
docker ps | grep httpd
# Should show: 0.0.0.0:80->80/tcp

# 3. Test from within container
docker exec -it httpd-1 wget -qO- http://localhost/site.json

# 4. Check firewall (Mac)
# System Preferences â†’ Security & Privacy â†’ Firewall
# Make sure Docker is allowed
```

**For Kubernetes:**
```bash
# NodePort:
# Verify with: kubectl get svc -n stc-vcp-services
# Access: http://localhost:30080

# Port-Forward:
# Restart: kubectl port-forward svc/... 9080:80 -n stc-vcp-services

# Ingress:
# Check: kubectl get ingress -n stc-vcp-services
```

### Issue: "Connection timeout" (not refused)

**Symptoms:**
- Request hangs and times out
- Different from "Connection refused" (which is immediate)

**Solution:**
```bash
# 1. Check pod is running and ready
kubectl get pods -n stc-vcp-services
# READY should be 1/1, not 0/1

# 2. Check service endpoints
kubectl get endpoints -n stc-vcp-services
# Should show IP addresses, not <none>

# 3. Check pod's container port
kubectl describe pod <pod-name> -n stc-vcp-services | grep Port

# 4. Test connectivity from another pod
kubectl run curl-test --image=curlimages/curl --rm -it --restart=Never -- \
  curl http://httpd-service.stc-vcp-services.svc.cluster.local

# 5. Check network policies (if any)
kubectl get networkpolicies -n stc-vcp-services
```

---

## Image and Registry Issues

### Issue: "manifest unknown" when pulling

**Error:**
```
manifest for nexus.telenity.com/.../httpd:1.0.0.1-amd64 not found
```

**Solution:**
```bash
# 1. Check image exists in registry
docker pull nexus.telenity.com/com/telenity/consolportals-sa-stc-vcp-httpd:1.0.0.1-amd64

# 2. If "not found", check tag name
docker images | grep httpd
# Verify exact tag name

# 3. If different, either:
# a) Push with correct tag
docker tag local/image nexus.telenity.com/.../httpd:1.0.0.1-amd64
docker push nexus.telenity.com/.../httpd:1.0.0.1-amd64

# b) Update values.yaml to match existing tag
```

### Issue: Multi-platform build not working

**Error:**
```
ERROR: failed to solve: executor failed running [/bin/sh -c ...]: exec format error
```

**Solution:**
```bash
# 1. Enable Docker buildx
docker buildx create --use

# 2. Build with explicit platform
docker buildx build --platform linux/amd64 \
  -t nexus.telenity.com/.../httpd:1.0.0.1-amd64 \
  --push \  # Note: --push required for buildx
  -f httpd/Dockerfile.vcp.prod \
  ./httpd

# 3. Verify architecture
docker pull nexus.telenity.com/.../httpd:1.0.0.1-amd64
docker inspect nexus.telenity.com/.../httpd:1.0.0.1-amd64 | grep Architecture
```

---

## Application-Specific Issues

### Issue: Portal returns 404

**Symptoms:**
- httpd/a3gw responding
- Portal paths return 404

**Solution:**
```bash
# 1. Check if portals are running
kubectl get pods -n stc-vcp-services | grep portal

# 2. Check portal container logs
kubectl logs <adminportal-pod> -n stc-vcp-services

# 3. Verify nginx is serving files
kubectl exec -it <adminportal-pod> -n stc-vcp-services -- ls /usr/share/nginx/html/adminportal

# 4. Test portal directly (bypass httpd and a3gw)
kubectl port-forward <adminportal-pod> 8080:8080 -n stc-vcp-services
curl http://localhost:8080/adminportal

# 5. Check httpd proxy configuration
kubectl exec -it <httpd-pod> -n stc-vcp-services -- cat /usr/local/apache2/conf.d/proxy.conf
```

### Issue: Authentication fails

**Symptoms:**
- Can access portal UI
- Login fails with error

**Solution:**
```bash
# 1. Check a3gw is routing to backend correctly
kubectl logs <a3gw-pod> -n stc-vcp-services

# 2. Check a3gw configuration
kubectl exec -it <a3gw-pod> -n stc-vcp-services -- cat /app/src/conf/service_proxies_config.json

# 3. Verify backend URL is reachable
# (This would be external to your cluster)

# 4. Check CORS settings in a3gw
# Look for allowed origins in config

# 5. Test authentication endpoint directly
kubectl port-forward <a3gw-pod> 8445:8445 -n stc-vcp-services
curl http://localhost:8445/cmpf-auth-rest/login -X POST -d '{...}'
```

### Issue: "CORS policy" error in browser

**Error in browser console:**
```
Access to fetch at '...' has been blocked by CORS policy
```

**Solution:**
```bash
# 1. Check browser developer console for full error

# 2. Verify httpd is adding correct CORS headers
kubectl exec -it <httpd-pod> -n stc-vcp-services -- \
  cat /usr/local/apache2/conf.d/security-headers.conf

# 3. Should include:
# Header set Access-Control-Allow-Origin "*"
# OR specific origin

# 4. Check a3gw proxy config
kubectl exec -it <a3gw-pod> -n stc-vcp-services -- \
  cat /app/src/conf/server_config.json
# Look for cors settings

# 5. For local testing, can disable browser CORS:
# Chrome: --disable-web-security --user-data-dir=/tmp/chrome
# (Don't use for production!)
```

---

## Quick Debugging Checklist

When something isn't working, go through this checklist:

### 1. Basic Health Check
```bash
# Docker
docker ps

# Kubernetes
kubectl get pods -n stc-vcp-services
kubectl get services -n stc-vcp-services
```

### 2. Check Logs
```bash
# Docker
docker logs <container-name> -f

# Kubernetes
kubectl logs <pod-name> -n stc-vcp-services -f
kubectl logs <pod-name> -n stc-vcp-services --previous  # If restarted
```

### 3. Check Events
```bash
# Kubernetes only
kubectl describe pod <pod-name> -n stc-vcp-services
kubectl get events -n stc-vcp-services --sort-by='.lastTimestamp'
```

### 4. Test Connectivity
```bash
# From your machine
curl http://localhost:30080/site.json

# From within cluster
kubectl run curl-test --image=curlimages/curl --rm -it --restart=Never -- \
  curl http://httpd-service.stc-vcp-services.svc.cluster.local/site.json
```

### 5. Verify Configuration
```bash
# Docker
docker exec -it <container> cat /path/to/config

# Kubernetes
kubectl exec -it <pod-name> -n stc-vcp-services -- cat /path/to/config
```

---

## Getting More Help

If you're still stuck after trying these solutions:

1. **Gather information:**
   ```bash
   # For Docker
   docker ps -a
   docker logs <container-name>
   docker-compose -f docker-compose_dev.yml config
   
   # For Kubernetes
   kubectl get all -n stc-vcp-services
   kubectl describe pod <failing-pod> -n stc-vcp-services
   kubectl logs <failing-pod> -n stc-vcp-services
   kubectl get events -n stc-vcp-services
   ```

2. **Check documentation:**
   - [GETTING-STARTED.md](2.%20GETTING-STARTED.md)
   - [README-Helm.md](README-Helm.md)
   - [README-LocalDevGuide.md](README-LocalDevGuide.md)

3. **Search for similar issues:**
   - Check project documentation
   - Search GitHub issues (if applicable)
   - Look for error messages online

4. **Ask for help:**
   - Include error messages
   - Describe what you tried
   - Share relevant logs
   - Mention your environment (Mac/Linux, Docker version, K8s version)

---

**Remember:** Most issues are caused by:
1. Port conflicts
2. Image pull problems
3. Configuration errors
4. Resource constraints
5. Network connectivity

Start with the basics (logs and status) and work your way up!
